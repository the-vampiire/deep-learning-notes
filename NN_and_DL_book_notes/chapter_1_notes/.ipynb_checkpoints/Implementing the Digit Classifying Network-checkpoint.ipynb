{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design `Network` class\n",
    "\n",
    "#### Notes:\n",
    "- must inherit the `object` class when creating the `Network` class (required for Python 2.x) [[source](https://stackoverflow.com/questions/4015417/python-class-inherits-object)]\n",
    "  - replace `class Network:` with `class Network(object):` if using Python 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "    \n",
    "    def feed_forward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = self.sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # mb_SGD = mini-batch stochastic gradient descent\n",
    "    def mb_SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        \"\"\"\n",
    "        Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  \n",
    "        \n",
    "        The \"training_data\" is a list of tuples\n",
    "        \"(x, y)\" representing the training inputs and the desired\n",
    "        outputs.\n",
    "        \n",
    "        The other non-optional parameters are\n",
    "        self-explanatory.\n",
    "        \n",
    "        If \"test_data\" is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out. This is useful for\n",
    "        tracking progress, but slows things down substantially.\n",
    "        \"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in xrange(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in xrange(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print \"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test)\n",
    "            else:\n",
    "                print \"Epoch {0} complete\".format(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Network - example network with `sizes = [2, 3, 1]`\n",
    "- **input layer**: 2 neurons\n",
    "- **hidden layer**: 3 neurons\n",
    "- **output layer**: 1 neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.feed_forward of <__main__.Network object at 0x1087ef3c8>>\n"
     ]
    }
   ],
   "source": [
    "nn = Network([2, 3, 1])\n",
    "print(nn.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sizes`\n",
    "- a 1d array containing an integer number of neurons per layer\n",
    "- **`sizes[:-1]`**: 1d array representing the number of neurons connected between the **input** and **hidden** layers\n",
    "- **`sizes[1:]`**: 1d array representing the number of neurons connected between the **hidden** and **output** layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes [:-1]:  [2, 3]\n",
      "sizes  [1:]:  [3, 1]\n"
     ]
    }
   ],
   "source": [
    "print('sizes [:-1]: ', nn.sizes[:-1])\n",
    "print('sizes  [1:]: ', nn.sizes[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `num_layers`\n",
    "- the number of layers in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers in the neural network: 3\n",
      "input layer: 2 neurons\n",
      "hidden layer(s): 3 total neurons\n",
      "output layer: 1 neurons\n"
     ]
    }
   ],
   "source": [
    "print('number of layers in the neural network: {}'.format(nn.num_layers))\n",
    "print('input layer: {} neurons'.format(nn.sizes[0]))\n",
    "print ('hidden layer(s): {} total neurons'.format(sum(nn.sizes[1:-1])))\n",
    "print('output layer: {} neurons'.format(nn.sizes[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `weights`\n",
    "- **note:** the input layer does not have any weights associated with it as they are simple input values\n",
    "- each element is an `nparray` holding the weights associated with the inputs of the previous layer into the next layer\n",
    "- prepared for stochastic gradient descent by randomly assigning Gaussian distributed values as a starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer [2 neurons] -> hidden layer [3 neurons] weights - 2x3 matrix:\n",
      "[[-0.11581554  0.94516819]\n",
      " [ 0.12787295  0.6695134 ]\n",
      " [ 2.13255741 -0.68516319]]\n",
      "\n",
      "input layer neurons [2 neurons] weights feeding hidden layer neuron 1: [-0.11581554  0.94516819]\n",
      "input layer neurons [2 neurons] weights feeding hidden layer neuron 2: [ 0.12787295  0.6695134 ]\n",
      "input layer neurons [2 neurons] weights feeding hidden layer neuron 2: [ 0.12787295  0.6695134 ]\n",
      "\n",
      "hidden layer neurons [3 neurons] -> output layer [1 neuron] weights - 1x3 matrix:\n",
      "[[ 0.39929956  0.6893374  -0.28006016]]\n"
     ]
    }
   ],
   "source": [
    "print('input layer [2 neurons] -> hidden layer [3 neurons] weights - 2x3 matrix:\\n{}\\n'.format(nn.weights[0]))\n",
    "print('input layer neurons [2 neurons] weights feeding hidden layer neuron 1: {}'.format(nn.weights[0][0]))\n",
    "print('input layer neurons [2 neurons] weights feeding hidden layer neuron 2: {}'.format(nn.weights[0][1]))\n",
    "print('input layer neurons [2 neurons] weights feeding hidden layer neuron 2: {}\\n'.format(nn.weights[0][1]))\n",
    "print('hidden layer neurons [3 neurons] -> output layer [1 neuron] weights - 1x3 matrix:\\n{}'.format(nn.weights[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `biases`\n",
    "- **note:** the input layer does not have any biases associated with its neurons as they are simple input values\n",
    "- each element is an `nparray` holding the biases associated with the neurons in that layer\n",
    "- prepared for stochastic gradient descent by randomly assigning Gaussian distributed values as a starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d nparray of biases [hidden and output layers]:\n",
      "[array([[-0.14699631],\n",
      "       [ 0.23296194],\n",
      "       [ 0.67244771]]), array([[-0.71364298]])]\n",
      "\n",
      "hidden layer [3 neurons] biases:\n",
      "[[-0.14699631]\n",
      " [ 0.23296194]\n",
      " [ 0.67244771]]\n",
      "\n",
      "bias of neuron 1 in the hidden layer:[-0.14699631]\n",
      "\n",
      "output layer [1 neuron] bias:[[-0.71364298]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('2d nparray of biases [hidden and output layers]:\\n{}\\n'.format(nn.biases))\n",
    "print('hidden layer [3 neurons] biases:\\n{}\\n'.format(nn.biases[0]))\n",
    "print('bias of neuron 1 in the hidden layer:{}\\n'.format(nn.biases[0][0]))\n",
    "print('output layer [1 neuron] bias:{}\\n'.format(nn.biases[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Sigmoid[σ]`  method\n",
    "- **note**: this method is defined in the class and explored in this section\n",
    "- accepts a numpy vector `z` and applies the `sigmoid function` element-wise\n",
    "- the `sigmoid function` is used to calculate the `activation vector` output of each neuron\n",
    "\n",
    "```\n",
    "def sigmoid(self, z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation vector: **`a′= σ(w·a + b)`**\n",
    "- **`a'`** --> activation vector (neuron output / input to neuron in the next layer)\n",
    "-  **`σ`** --> sigmoid function\n",
    "- **`w`** --> matrix of weights\n",
    "- **`a`** --> matrix of activation vectors\n",
    "- **`b`** --> matrix of biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `feedforward` method\n",
    "- **note**: this method is defined in the class and explored in this section\n",
    "```\n",
    "def feed_forward(self, a):\n",
    "    for w, b in zip(self.weights, self.biases):\n",
    "        a = self.sigmoid(np.dot(w, a) + b)\n",
    "    return a\n",
    "```\n",
    "\n",
    "### QUESTIONS\n",
    "- **input**: `a` --> activation vector from the previous layer\n",
    "- **output**: `a'` --> activation vector output of the current layer\n",
    "- isnt the argument `a` being overwritten in each iteration of the loop?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch Stochastic Gradient Descent\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/aZ3LDBs1ExsE8/giphy.gif\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
